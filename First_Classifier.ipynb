{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import itertools\n",
    "import xlrd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heavy weight classifier tools\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_cm(X, y, num_tests):\n",
    "    # cm_list is a list of confusion matrices for the different random splits of the dataset\n",
    "    cm_list = []\n",
    "    \n",
    "    for i in range(0,num_tests):\n",
    "        X_train_loop, X_test_loop, y_train_loop, y_test_loop = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))\n",
    "\n",
    "        # train a logistic regression classifier\n",
    "        clf_loop = GaussianNB().fit(X_train_loop, y_train_loop) #(C=1.0).fit(X_train_loop, y_train_loop)\n",
    "\n",
    "        # predict on train and test set\n",
    "        y_train_predict_loop = clf_loop.predict(X_train_loop)\n",
    "        y_test_predict_loop = clf_loop.predict(X_test_loop)\n",
    "        cm_list.append(confusion_matrix(y_test_loop, y_test_predict_loop))\n",
    "    \n",
    "    # sum the confusion matrices and return the combined confusion matrix\n",
    "    combined_cm = pd.Panel(cm_list).sum(axis=0)\n",
    "    \n",
    "    # validate return type\n",
    "    assert isinstance(combined_cm, pd.DataFrame), \"return type\"\n",
    "    \n",
    "    return combined_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm):\n",
    "    # plot the confusion matrix\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.matshow(cm, fignum=1)\n",
    "    \n",
    "    # add labels for all targets\n",
    "    num_targets = cm.shape[0]\n",
    "    plt.xticks(list(range(num_targets+1)))\n",
    "    plt.yticks(list(range(num_targets+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_Reg(X, y):\n",
    "    # result_list is a list of tuples (of train and test accuracy for each preset regularization threshold\n",
    "    result_list = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))\n",
    "    \n",
    "    for param in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
    "        \n",
    "        clf_loop = LogisticRegression(C=param).fit(X_train, y_train)\n",
    "        \n",
    "        y_train_predict = clf_loop.predict(X_train)\n",
    "        y_test_predict = clf_loop.predict(X_test)\n",
    "        \n",
    "        train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "        test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "        \n",
    "        # add to result_list\n",
    "        result_list.append((param, train_accuracy, test_accuracy))\n",
    "        \n",
    "    # Make a dataframe of the results\n",
    "    result_df = pd.DataFrame(result_list, columns=[\"param\", \"train_accuracy\", \"test_accuracy\"])\n",
    "    \n",
    "    # validate return type\n",
    "    assert isinstance(result_df, pd.DataFrame), \"return type\"\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_RanFor(X, y):\n",
    "    # result_list is a list of tuples (of train and test accuracy for each preset regularization threshold\n",
    "    result_list = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))\n",
    "    n_est = [1500]\n",
    "    max_dep = [10, 15, 20]\n",
    "    \n",
    "    for i in n_est:\n",
    "        for j in max_dep:\n",
    "        \n",
    "            clf_loop = RandomForestClassifier(n_estimators=i, max_depth=j, random_state=random.randint(1,1000))\n",
    "            clf_loop.fit(X_train, y_train)\n",
    "        \n",
    "            y_train_predict = clf_loop.predict(X_train)\n",
    "            y_test_predict = clf_loop.predict(X_test)\n",
    "        \n",
    "            train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "            test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "        \n",
    "            # add to result_list\n",
    "            result_list.append((i, j, train_accuracy, test_accuracy))\n",
    "        \n",
    "    # Make a dataframe of the results\n",
    "    result_df = pd.DataFrame(result_list, columns=[\"Number of Estimators\", \"Max Depth\", \"train_accuracy\", \"test_accuracy\"])\n",
    "    \n",
    "    # validate return type\n",
    "    assert isinstance(result_df, pd.DataFrame), \"return type\"\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Classifier Training (first pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeledDF = pd.read_excel('Labelled_Data.xlsx', sheet_name='Output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = labeledDF.loc[:, labeledDF.columns != 'Building_Typology']\n",
    "y = labeledDF.loc[:, labeledDF.columns == 'Building_Typology']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.661749209694\n",
      "Test accuracy: 0.641728134879\n"
     ]
    }
   ],
   "source": [
    "# train a logistic regression classifier\n",
    "clf = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "\n",
    "# predict on train and test set\n",
    "y_train_predict = clf.predict(X_train)\n",
    "y_test_predict = clf.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:2: FutureWarning: \n",
      "Panel is deprecated and will be removed in a future version.\n",
      "The recommended way to represent these types of 3-dimensional data are with a MultiIndex on a DataFrame, via the Panel.to_frame() method\n",
      "Alternatively, you can use the xarray package http://xarray.pydata.org/en/stable/.\n",
      "Pandas provides a `.to_xarray()` method to help automate this conversion.\n",
      "\n",
      "  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for plotting the confusion matrix\n",
    "cm10 = random_cm(X, y, num_tests = 10)\n",
    "plot_confusion_matrix(cm10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Using a Random Forest Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modifying input as necessary\n",
    "X_train2 = X_train.drop(['Latitude Quadrant', 'Longitude Quadrant'], axis=1).copy()\n",
    "X_test2 = X_test.drop(['Latitude Quadrant', 'Longitude Quadrant'], axis=1).copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clf2.fit(X_train2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.853530031612\n",
      "Test accuracy: 0.71057253249\n"
     ]
    }
   ],
   "source": [
    "#WITH LAT AND LON SECTOR\n",
    "# predict on train and test set (random forest)\n",
    "y_train_predict2 = clf2.predict(X_train2)\n",
    "y_test_predict2 = clf2.predict(X_test2)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy2 = accuracy_score(y_train, y_train_predict2)\n",
    "test_accuracy2 = accuracy_score(y_test, y_test_predict2)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy2))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.832003612826\n",
      "Test accuracy: 0.68387776607\n"
     ]
    }
   ],
   "source": [
    "#WITHOUT LAT AND LON SECTOR\n",
    "# predict on train and test set (random forest)\n",
    "y_train_predict2 = clf2.predict(X_train2)\n",
    "y_test_predict2 = clf2.predict(X_test2)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy2 = accuracy_score(y_train, y_train_predict2)\n",
    "test_accuracy2 = accuracy_score(y_test, y_test_predict2)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy2))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy2))\n",
    "\n",
    "#slightly lower, it was learning something from the sector after all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'Apartment', u'Attached House', u'Commercial', u'Detached House',\n",
       "       u'Industrial', u'Institutional', u'Office', u'Small Commercial'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we're not just naively guessing Detached house!\n",
    "np.unique(y_test_predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, y_test_predict2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = np.unique(y_test)\n",
    "resultDF = pd.DataFrame(confusion_matrix(y_test, y_test_predict2, labels=unique_label), index=['true:{:}'.format(x) for x in unique_label],columns=['pred:{:}'.format(x) for x in unique_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:Apartment</th>\n",
       "      <th>pred:Attached House</th>\n",
       "      <th>pred:Commercial</th>\n",
       "      <th>pred:Detached House</th>\n",
       "      <th>pred:Industrial</th>\n",
       "      <th>pred:Institutional</th>\n",
       "      <th>pred:Office</th>\n",
       "      <th>pred:Small Commercial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true:Apartment</th>\n",
       "      <td>70</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Attached House</th>\n",
       "      <td>5</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Commercial</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Detached House</th>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>1647</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Industrial</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Institutional</th>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Office</th>\n",
       "      <td>21</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Small Commercial</th>\n",
       "      <td>27</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pred:Apartment  pred:Attached House  pred:Commercial  \\\n",
       "true:Apartment                     70                   14                1   \n",
       "true:Attached House                 5                  211                0   \n",
       "true:Commercial                     4                    3                0   \n",
       "true:Detached House                 5                   79                2   \n",
       "true:Industrial                     1                    2                0   \n",
       "true:Institutional                 12                    4                0   \n",
       "true:Office                        21                   13                0   \n",
       "true:Small Commercial              27                   19                0   \n",
       "\n",
       "                       pred:Detached House  pred:Industrial  \\\n",
       "true:Apartment                          50                0   \n",
       "true:Attached House                    244                0   \n",
       "true:Commercial                          8                0   \n",
       "true:Detached House                   1647                0   \n",
       "true:Industrial                          8                8   \n",
       "true:Institutional                      24                2   \n",
       "true:Office                             19                1   \n",
       "true:Small Commercial                   61                8   \n",
       "\n",
       "                       pred:Institutional  pred:Office  pred:Small Commercial  \n",
       "true:Apartment                          1            8                     34  \n",
       "true:Attached House                     0            1                     18  \n",
       "true:Commercial                         4            2                      9  \n",
       "true:Detached House                     1            0                     18  \n",
       "true:Industrial                         1            2                     22  \n",
       "true:Institutional                      2            7                     20  \n",
       "true:Office                             2           19                     24  \n",
       "true:Small Commercial                   2           11                     66  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we very rarely predict commercial, and our small commercial is very noisy. \n",
    "resultDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = labeledDF.loc[:, labeledDF.columns != 'Building_Typology']\n",
    "y = labeledDF.loc[:, labeledDF.columns == 'Building_Typology']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=random.randint(1,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()  \n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100, 500), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=197, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6 = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(100, 500), random_state=random.randint(1,1000))\n",
    "clf6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.782778864971\n",
      "Test accuracy: 0.702493853179\n"
     ]
    }
   ],
   "source": [
    "# predict on train and test set (neural net)\n",
    "y_train_predict = clf6.predict(X_train)\n",
    "y_test_predict = clf6.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))\n",
    "#not that good all in all, definitely need to do heirarchical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breaking out prediction into heirarchical steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a new DF for predicting higher-level class\n",
    "topLevelDF = labeledDF.copy()\n",
    "topLevelDF['class'] = \"non-domestic\"\n",
    "topLevelDF.loc[topLevelDF.Building_Typology == \"Detached House\", 'class'] = 'domestic'\n",
    "topLevelDF.loc[topLevelDF.Building_Typology == \"Attached House\", 'class'] = 'domestic'\n",
    "topLevelDF = topLevelDF.drop(['Building_Typology'], axis=1)\n",
    "\n",
    "#defining new testing and training sets\n",
    "X = topLevelDF.loc[:, topLevelDF.columns != 'class']\n",
    "y = topLevelDF.loc[:, topLevelDF.columns == 'class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random.randint(1,1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = LogisticRegression(C=1.0).fit(X_train, y_train)\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.896281800391\n",
      "Test accuracy: 0.895328415876\n"
     ]
    }
   ],
   "source": [
    "#WITH LAT AND LON SECTOR\n",
    "# predict on train and test set (random forest)\n",
    "y_train_predict = clf3.predict(X_train)\n",
    "y_test_predict = clf3.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))\n",
    "#worse with this, oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16734e80>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hyperparameter tuning the logistic regression classifier\n",
    "param_df = hyperparameter_Reg(X, y)\n",
    "param_df.plot(x=\"param\", y=[\"train_accuracy\", \"test_accuracy\"], logx=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.945506548246\n",
      "Test accuracy: 0.912539515279\n"
     ]
    }
   ],
   "source": [
    "#WITH LAT AND LON SECTOR\n",
    "# predict on train and test set (random forest)\n",
    "y_train_predict = clf3.predict(X_train)\n",
    "y_test_predict = clf3.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))\n",
    "#not exceptional performance, can we really not get into the high 90s for this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:13: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Estimators</th>\n",
       "      <th>Max Depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1500</td>\n",
       "      <td>10</td>\n",
       "      <td>0.944754</td>\n",
       "      <td>0.914296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1500</td>\n",
       "      <td>15</td>\n",
       "      <td>0.959657</td>\n",
       "      <td>0.913593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500</td>\n",
       "      <td>20</td>\n",
       "      <td>0.971850</td>\n",
       "      <td>0.913242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Estimators  Max Depth  train_accuracy  test_accuracy\n",
       "0                  1500         10        0.944754       0.914296\n",
       "1                  1500         15        0.959657       0.913593\n",
       "2                  1500         20        0.971850       0.913242"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Appears to be the best, hyperparameter tuning over a reasonable set of parameters\n",
    "hyperparameter_RanFor(X, y)\n",
    "#best performance is around 10 depth with 1500 estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Naive Bayes (all 3 major variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_MN = MultinomialNB().fit(X_train, y_train)\n",
    "clf_GS = GaussianNB().fit(X_train, y_train)\n",
    "clf_BL = BernoulliNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_MN.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GS.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_BL.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.794520547945\n",
      "Test accuracy: 0.794871794872\n"
     ]
    }
   ],
   "source": [
    "#WITH LAT AND LON SECTOR\n",
    "# predict on train and test set (random forest)\n",
    "y_train_predict = clf_BL.predict(X_train)\n",
    "y_test_predict = clf_BL.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))\n",
    "#not exceptional performance, can we really not get into the high 90s for this?\n",
    "#MN has roughly 86% test accuracy\n",
    "#GS has roughly 88% test accuracy\n",
    "#BL has roughly 79% test accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Typology Classification in domestic/non-domestic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topLevelDF = labeledDF.copy()\n",
    "topLevelDF['class'] = \"non-domestic\"\n",
    "topLevelDF.loc[topLevelDF.Building_Typology == \"Detached House\", 'class'] = 'domestic'\n",
    "topLevelDF.loc[topLevelDF.Building_Typology == \"Attached House\", 'class'] = 'domestic'\n",
    "\n",
    "domesticDF = topLevelDF.loc[topLevelDF['class'] == \"domestic\"].drop(['class'],axis=1).copy()\n",
    "nonDomesticDF = topLevelDF.loc[topLevelDF['class'] == \"non-domestic\"].drop(['class'],axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the Domestic Typologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.910786387233\n",
      "Test accuracy: 0.867653656348\n"
     ]
    }
   ],
   "source": [
    "X = domesticDF.loc[:, domesticDF.columns != 'Building_Typology']\n",
    "y = domesticDF.loc[:, domesticDF.columns == 'Building_Typology']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random.randint(1,1000))\n",
    "\n",
    "clf4 = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=42)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = clf4.predict(X_train)\n",
    "y_test_predict = clf4.predict(X_test)\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = np.unique(y_test)\n",
    "resultDF = pd.DataFrame(confusion_matrix(y_test, y_test_predict, labels=unique_label), index=['true:{:}'.format(x) for x in unique_label],columns=['pred:{:}'.format(x) for x in unique_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:Attached House</th>\n",
       "      <th>pred:Detached House</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true:Attached House</th>\n",
       "      <td>211</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Detached House</th>\n",
       "      <td>95</td>\n",
       "      <td>1723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pred:Attached House  pred:Detached House\n",
       "true:Attached House                  211                  200\n",
       "true:Detached House                   95                 1723"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on Non-Domestic Typologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n",
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Anaconda\\envs\\warmup\\lib\\site-packages\\ipykernel_launcher.py:12: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.883495145631\n",
      "Test accuracy: 0.427184466019\n"
     ]
    }
   ],
   "source": [
    "X = nonDomesticDF.loc[:, domesticDF.columns != 'Building_Typology']\n",
    "y = nonDomesticDF.loc[:, domesticDF.columns == 'Building_Typology']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #random.randint(1,1000))\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(X_train)  \n",
    "X_train = scaler.transform(X_train)  \n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "clf5 = RandomForestClassifier(n_estimators=2000, max_depth=10, random_state=42)\n",
    "#clf5 = MLPClassifier(solver='lbfgs', alpha=0.01, hidden_layer_sizes=(100, 50), random_state=random.randint(1,1000))\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = clf5.predict(X_train)\n",
    "y_test_predict = clf5.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "# calculate train and test accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_predict)\n",
    "test_accuracy = accuracy_score(y_test, y_test_predict)\n",
    "\n",
    "# report results\n",
    "print(\"Train accuracy: {}\".format(train_accuracy))\n",
    "print(\"Test accuracy: {}\".format(test_accuracy))\n",
    "#look like massive overfitting!\n",
    "#Random Forest, ~40% accuracy\n",
    "#MLP, ~32% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label = np.unique(y_test)\n",
    "resultDF = pd.DataFrame(confusion_matrix(y_test, y_test_predict, labels=unique_label), index=['true:{:}'.format(x) for x in unique_label],columns=['pred:{:}'.format(x) for x in unique_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIN_HEIGHT</th>\n",
       "      <th>MAX_HEIGHT</th>\n",
       "      <th>AVG_HEIGHT</th>\n",
       "      <th>SHAPE_LENG</th>\n",
       "      <th>SHAPE_AREA</th>\n",
       "      <th>Simple Volume</th>\n",
       "      <th>Simple Surface Area</th>\n",
       "      <th>Latitude Quadrant</th>\n",
       "      <th>Longitude Quadrant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.8253</td>\n",
       "      <td>5.7400</td>\n",
       "      <td>61.535222</td>\n",
       "      <td>183.015834</td>\n",
       "      <td>1050.510885</td>\n",
       "      <td>10303.293150</td>\n",
       "      <td>134</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.5232</td>\n",
       "      <td>4.3652</td>\n",
       "      <td>55.845443</td>\n",
       "      <td>123.957598</td>\n",
       "      <td>541.099705</td>\n",
       "      <td>8927.413959</td>\n",
       "      <td>130</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.3671</td>\n",
       "      <td>7.9324</td>\n",
       "      <td>6.3917</td>\n",
       "      <td>61.068415</td>\n",
       "      <td>233.001275</td>\n",
       "      <td>1489.274248</td>\n",
       "      <td>6953.727742</td>\n",
       "      <td>23</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.2157</td>\n",
       "      <td>2.8287</td>\n",
       "      <td>72.092664</td>\n",
       "      <td>205.232819</td>\n",
       "      <td>580.542076</td>\n",
       "      <td>7817.986839</td>\n",
       "      <td>24</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.1560</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>49.573200</td>\n",
       "      <td>101.145019</td>\n",
       "      <td>6.776716</td>\n",
       "      <td>5110.582173</td>\n",
       "      <td>20</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.3559</td>\n",
       "      <td>4.1002</td>\n",
       "      <td>137.007253</td>\n",
       "      <td>827.570865</td>\n",
       "      <td>3393.206061</td>\n",
       "      <td>17878.444612</td>\n",
       "      <td>53</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.9499</td>\n",
       "      <td>4.6419</td>\n",
       "      <td>79.742656</td>\n",
       "      <td>396.594760</td>\n",
       "      <td>1840.953217</td>\n",
       "      <td>10165.902061</td>\n",
       "      <td>54</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.3481</td>\n",
       "      <td>3.9839</td>\n",
       "      <td>64.241934</td>\n",
       "      <td>232.347613</td>\n",
       "      <td>925.649655</td>\n",
       "      <td>7834.208723</td>\n",
       "      <td>45</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.0620</td>\n",
       "      <td>5.3835</td>\n",
       "      <td>198.831334</td>\n",
       "      <td>2088.626349</td>\n",
       "      <td>11244.119950</td>\n",
       "      <td>27585.864459</td>\n",
       "      <td>51</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.5458</td>\n",
       "      <td>3.9654</td>\n",
       "      <td>89.005506</td>\n",
       "      <td>383.901597</td>\n",
       "      <td>1522.323394</td>\n",
       "      <td>11359.992439</td>\n",
       "      <td>54</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>50.0660</td>\n",
       "      <td>36.5440</td>\n",
       "      <td>162.237672</td>\n",
       "      <td>972.965647</td>\n",
       "      <td>35556.056588</td>\n",
       "      <td>27843.444169</td>\n",
       "      <td>78</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.3362</td>\n",
       "      <td>4.5923</td>\n",
       "      <td>203.432792</td>\n",
       "      <td>2282.942254</td>\n",
       "      <td>10483.955715</td>\n",
       "      <td>29040.883717</td>\n",
       "      <td>63</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.3692</td>\n",
       "      <td>5.4736</td>\n",
       "      <td>310.249974</td>\n",
       "      <td>1978.129188</td>\n",
       "      <td>10827.487921</td>\n",
       "      <td>41619.054015</td>\n",
       "      <td>60</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>9.0163</td>\n",
       "      <td>6.9117</td>\n",
       "      <td>138.219014</td>\n",
       "      <td>1053.829010</td>\n",
       "      <td>7283.749967</td>\n",
       "      <td>19034.787783</td>\n",
       "      <td>63</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>162.636858</td>\n",
       "      <td>1158.026030</td>\n",
       "      <td>6948.156183</td>\n",
       "      <td>22375.519478</td>\n",
       "      <td>63</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.1360</td>\n",
       "      <td>6.4386</td>\n",
       "      <td>24.214510</td>\n",
       "      <td>43.716153</td>\n",
       "      <td>281.470823</td>\n",
       "      <td>3432.521596</td>\n",
       "      <td>91</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>41.1000</td>\n",
       "      <td>146.802791</td>\n",
       "      <td>1423.614241</td>\n",
       "      <td>58510.545325</td>\n",
       "      <td>27124.006083</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>48.5600</td>\n",
       "      <td>83.144514</td>\n",
       "      <td>319.245063</td>\n",
       "      <td>15502.540260</td>\n",
       "      <td>15116.444333</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.7750</td>\n",
       "      <td>5.1802</td>\n",
       "      <td>312.490486</td>\n",
       "      <td>3092.842522</td>\n",
       "      <td>16021.542831</td>\n",
       "      <td>50333.090914</td>\n",
       "      <td>103</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.1521</td>\n",
       "      <td>3.7707</td>\n",
       "      <td>60.907050</td>\n",
       "      <td>191.873300</td>\n",
       "      <td>723.496651</td>\n",
       "      <td>9003.738700</td>\n",
       "      <td>106</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>51.6780</td>\n",
       "      <td>36.3080</td>\n",
       "      <td>142.533545</td>\n",
       "      <td>766.598459</td>\n",
       "      <td>27833.656849</td>\n",
       "      <td>26248.941234</td>\n",
       "      <td>98</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>43.8900</td>\n",
       "      <td>43.464029</td>\n",
       "      <td>86.955970</td>\n",
       "      <td>3816.497502</td>\n",
       "      <td>8421.211415</td>\n",
       "      <td>124</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3.2800</td>\n",
       "      <td>398.657051</td>\n",
       "      <td>4482.566926</td>\n",
       "      <td>14702.819519</td>\n",
       "      <td>67615.559255</td>\n",
       "      <td>111</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.3400</td>\n",
       "      <td>205.750383</td>\n",
       "      <td>1950.018734</td>\n",
       "      <td>14313.137508</td>\n",
       "      <td>35085.623016</td>\n",
       "      <td>110</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>19.5100</td>\n",
       "      <td>81.830901</td>\n",
       "      <td>414.007375</td>\n",
       "      <td>8077.283891</td>\n",
       "      <td>14066.617857</td>\n",
       "      <td>108</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>48.1700</td>\n",
       "      <td>70.720246</td>\n",
       "      <td>303.287734</td>\n",
       "      <td>14609.370146</td>\n",
       "      <td>14185.569959</td>\n",
       "      <td>111</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.5483</td>\n",
       "      <td>4.1888</td>\n",
       "      <td>142.855554</td>\n",
       "      <td>1035.200691</td>\n",
       "      <td>4336.248653</td>\n",
       "      <td>23381.735801</td>\n",
       "      <td>125</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.7020</td>\n",
       "      <td>5.0070</td>\n",
       "      <td>72.721782</td>\n",
       "      <td>277.858797</td>\n",
       "      <td>1391.238999</td>\n",
       "      <td>11619.827741</td>\n",
       "      <td>132</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.6400</td>\n",
       "      <td>5.9445</td>\n",
       "      <td>82.474192</td>\n",
       "      <td>413.104811</td>\n",
       "      <td>2455.701547</td>\n",
       "      <td>13723.358799</td>\n",
       "      <td>140</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.5301</td>\n",
       "      <td>4.3241</td>\n",
       "      <td>310.482579</td>\n",
       "      <td>4625.250677</td>\n",
       "      <td>20000.046451</td>\n",
       "      <td>60151.946864</td>\n",
       "      <td>172</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9251</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.6364</td>\n",
       "      <td>2.8513</td>\n",
       "      <td>27.567611</td>\n",
       "      <td>44.123279</td>\n",
       "      <td>125.808706</td>\n",
       "      <td>3702.470687</td>\n",
       "      <td>333</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9272</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.9800</td>\n",
       "      <td>341.604876</td>\n",
       "      <td>4609.798914</td>\n",
       "      <td>22956.798594</td>\n",
       "      <td>49820.020507</td>\n",
       "      <td>338</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9281</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.1960</td>\n",
       "      <td>4.6218</td>\n",
       "      <td>60.008020</td>\n",
       "      <td>169.293600</td>\n",
       "      <td>782.441160</td>\n",
       "      <td>8222.800977</td>\n",
       "      <td>376</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9286</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>23.0570</td>\n",
       "      <td>5.2358</td>\n",
       "      <td>250.872987</td>\n",
       "      <td>1997.884623</td>\n",
       "      <td>10460.524311</td>\n",
       "      <td>34789.675730</td>\n",
       "      <td>354</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9287</th>\n",
       "      <td>0.0104</td>\n",
       "      <td>12.8810</td>\n",
       "      <td>7.2467</td>\n",
       "      <td>136.419116</td>\n",
       "      <td>875.652788</td>\n",
       "      <td>6345.593058</td>\n",
       "      <td>18830.706012</td>\n",
       "      <td>357</td>\n",
       "      <td>446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9289</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.8362</td>\n",
       "      <td>5.1473</td>\n",
       "      <td>59.223701</td>\n",
       "      <td>182.489157</td>\n",
       "      <td>939.326437</td>\n",
       "      <td>7838.298710</td>\n",
       "      <td>353</td>\n",
       "      <td>442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.3130</td>\n",
       "      <td>4.6955</td>\n",
       "      <td>140.414824</td>\n",
       "      <td>668.889915</td>\n",
       "      <td>3140.772595</td>\n",
       "      <td>19809.630797</td>\n",
       "      <td>346</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9296</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.8709</td>\n",
       "      <td>5.0148</td>\n",
       "      <td>74.672548</td>\n",
       "      <td>224.923228</td>\n",
       "      <td>1127.945005</td>\n",
       "      <td>10277.425804</td>\n",
       "      <td>349</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9300</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.9040</td>\n",
       "      <td>6.1106</td>\n",
       "      <td>462.694359</td>\n",
       "      <td>5577.503988</td>\n",
       "      <td>34081.895872</td>\n",
       "      <td>72154.318799</td>\n",
       "      <td>341</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.5230</td>\n",
       "      <td>4.8424</td>\n",
       "      <td>91.871486</td>\n",
       "      <td>472.079746</td>\n",
       "      <td>2285.998962</td>\n",
       "      <td>13761.793582</td>\n",
       "      <td>346</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.9900</td>\n",
       "      <td>7.1321</td>\n",
       "      <td>213.520118</td>\n",
       "      <td>2696.776875</td>\n",
       "      <td>19233.682352</td>\n",
       "      <td>37379.935090</td>\n",
       "      <td>400</td>\n",
       "      <td>424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.5990</td>\n",
       "      <td>8.1287</td>\n",
       "      <td>178.866286</td>\n",
       "      <td>1879.712774</td>\n",
       "      <td>15279.621224</td>\n",
       "      <td>30355.769037</td>\n",
       "      <td>402</td>\n",
       "      <td>427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.4823</td>\n",
       "      <td>4.0771</td>\n",
       "      <td>89.433691</td>\n",
       "      <td>355.824549</td>\n",
       "      <td>1450.732270</td>\n",
       "      <td>14215.778681</td>\n",
       "      <td>403</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9312</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>17.9030</td>\n",
       "      <td>5.7323</td>\n",
       "      <td>476.940794</td>\n",
       "      <td>4794.236478</td>\n",
       "      <td>27482.001763</td>\n",
       "      <td>84063.254807</td>\n",
       "      <td>398</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9321</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>26.8560</td>\n",
       "      <td>18.3260</td>\n",
       "      <td>431.474963</td>\n",
       "      <td>6311.881900</td>\n",
       "      <td>115671.547697</td>\n",
       "      <td>72705.789391</td>\n",
       "      <td>373</td>\n",
       "      <td>428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9323</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>47.6720</td>\n",
       "      <td>37.1120</td>\n",
       "      <td>148.644044</td>\n",
       "      <td>921.541618</td>\n",
       "      <td>34200.252519</td>\n",
       "      <td>25832.002277</td>\n",
       "      <td>374</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9324</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.3276</td>\n",
       "      <td>4.2714</td>\n",
       "      <td>88.626625</td>\n",
       "      <td>375.112771</td>\n",
       "      <td>1602.256689</td>\n",
       "      <td>13567.053597</td>\n",
       "      <td>380</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9325</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>236.404198</td>\n",
       "      <td>1922.878354</td>\n",
       "      <td>8652.952594</td>\n",
       "      <td>39812.055044</td>\n",
       "      <td>401</td>\n",
       "      <td>422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>25.7220</td>\n",
       "      <td>16.9150</td>\n",
       "      <td>366.985413</td>\n",
       "      <td>3817.323403</td>\n",
       "      <td>64570.025362</td>\n",
       "      <td>65807.706484</td>\n",
       "      <td>375</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9343</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.3220</td>\n",
       "      <td>7.6258</td>\n",
       "      <td>353.445190</td>\n",
       "      <td>7464.020802</td>\n",
       "      <td>56919.129831</td>\n",
       "      <td>69928.707974</td>\n",
       "      <td>411</td>\n",
       "      <td>426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9346</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>8.9094</td>\n",
       "      <td>5.4171</td>\n",
       "      <td>681.828395</td>\n",
       "      <td>6870.268200</td>\n",
       "      <td>37216.929867</td>\n",
       "      <td>119293.708343</td>\n",
       "      <td>408</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9361</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>188.860351</td>\n",
       "      <td>785.240245</td>\n",
       "      <td>3140.960978</td>\n",
       "      <td>20287.240105</td>\n",
       "      <td>338</td>\n",
       "      <td>461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9379</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.8926</td>\n",
       "      <td>3.9517</td>\n",
       "      <td>123.867586</td>\n",
       "      <td>747.094415</td>\n",
       "      <td>2952.293001</td>\n",
       "      <td>21911.406828</td>\n",
       "      <td>369</td>\n",
       "      <td>450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9395</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.2597</td>\n",
       "      <td>3.9638</td>\n",
       "      <td>63.769752</td>\n",
       "      <td>208.166747</td>\n",
       "      <td>825.131352</td>\n",
       "      <td>7603.694732</td>\n",
       "      <td>375</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9410</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>11.8060</td>\n",
       "      <td>4.3860</td>\n",
       "      <td>64.872840</td>\n",
       "      <td>181.890278</td>\n",
       "      <td>797.770760</td>\n",
       "      <td>7632.847189</td>\n",
       "      <td>356</td>\n",
       "      <td>462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9426</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>6.0949</td>\n",
       "      <td>4.4083</td>\n",
       "      <td>130.450836</td>\n",
       "      <td>938.374900</td>\n",
       "      <td>4136.638071</td>\n",
       "      <td>17680.868540</td>\n",
       "      <td>397</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9458</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.0179</td>\n",
       "      <td>4.7674</td>\n",
       "      <td>56.280399</td>\n",
       "      <td>133.566004</td>\n",
       "      <td>636.762566</td>\n",
       "      <td>6673.360979</td>\n",
       "      <td>394</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9460</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>10.5110</td>\n",
       "      <td>6.8862</td>\n",
       "      <td>268.106349</td>\n",
       "      <td>3078.929633</td>\n",
       "      <td>21202.125237</td>\n",
       "      <td>32522.740580</td>\n",
       "      <td>372</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9481</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>7.1706</td>\n",
       "      <td>5.1042</td>\n",
       "      <td>84.231701</td>\n",
       "      <td>406.946663</td>\n",
       "      <td>2077.137158</td>\n",
       "      <td>10600.774629</td>\n",
       "      <td>403</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9485</th>\n",
       "      <td>1.0084</td>\n",
       "      <td>18.1490</td>\n",
       "      <td>3.0532</td>\n",
       "      <td>41.443501</td>\n",
       "      <td>83.173844</td>\n",
       "      <td>253.946380</td>\n",
       "      <td>3474.347194</td>\n",
       "      <td>72</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2060 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MIN_HEIGHT  MAX_HEIGHT  AVG_HEIGHT  SHAPE_LENG   SHAPE_AREA  \\\n",
       "0         0.0000      9.8253      5.7400   61.535222   183.015834   \n",
       "4         0.0000      6.5232      4.3652   55.845443   123.957598   \n",
       "6         3.3671      7.9324      6.3917   61.068415   233.001275   \n",
       "7         0.0000      5.2157      2.8287   72.092664   205.232819   \n",
       "17        0.0000      2.1560      0.0670   49.573200   101.145019   \n",
       "37        0.0000      7.3559      4.1002  137.007253   827.570865   \n",
       "38        0.0000      8.9499      4.6419   79.742656   396.594760   \n",
       "46        0.0000      6.3481      3.9839   64.241934   232.347613   \n",
       "59        0.0000     10.0620      5.3835  198.831334  2088.626349   \n",
       "60        0.0000      6.5458      3.9654   89.005506   383.901597   \n",
       "61        0.0000     50.0660     36.5440  162.237672   972.965647   \n",
       "68        0.0000      8.3362      4.5923  203.432792  2282.942254   \n",
       "69        0.0000      8.3692      5.4736  310.249974  1978.129188   \n",
       "70        0.0000      9.0163      6.9117  138.219014  1053.829010   \n",
       "75        0.0000      0.0000      6.0000  162.636858  1158.026030   \n",
       "76        0.0000     11.1360      6.4386   24.214510    43.716153   \n",
       "77        0.0000      0.0000     41.1000  146.802791  1423.614241   \n",
       "78        0.0000      0.0000     48.5600   83.144514   319.245063   \n",
       "91        0.0000     10.7750      5.1802  312.490486  3092.842522   \n",
       "107       0.0000      6.1521      3.7707   60.907050   191.873300   \n",
       "118       0.0000     51.6780     36.3080  142.533545   766.598459   \n",
       "119       0.0000      0.0000     43.8900   43.464029    86.955970   \n",
       "120       0.0000      0.0000      3.2800  398.657051  4482.566926   \n",
       "121       0.0000      0.0000      7.3400  205.750383  1950.018734   \n",
       "122       0.0000      0.0000     19.5100   81.830901   414.007375   \n",
       "123       0.0000      0.0000     48.1700   70.720246   303.287734   \n",
       "130       0.0000      7.5483      4.1888  142.855554  1035.200691   \n",
       "137       0.0000     10.7020      5.0070   72.721782   277.858797   \n",
       "140       0.0000     11.6400      5.9445   82.474192   413.104811   \n",
       "152       0.0000      7.5301      4.3241  310.482579  4625.250677   \n",
       "...          ...         ...         ...         ...          ...   \n",
       "9251      0.0000      5.6364      2.8513   27.567611    44.123279   \n",
       "9272      0.0000      0.0000      4.9800  341.604876  4609.798914   \n",
       "9281      0.0000     11.1960      4.6218   60.008020   169.293600   \n",
       "9286      0.0000     23.0570      5.2358  250.872987  1997.884623   \n",
       "9287      0.0104     12.8810      7.2467  136.419116   875.652788   \n",
       "9289      0.0000      8.8362      5.1473   59.223701   182.489157   \n",
       "9294      0.0000     12.3130      4.6955  140.414824   668.889915   \n",
       "9296      0.0000      7.8709      5.0148   74.672548   224.923228   \n",
       "9300      0.0000     11.9040      6.1106  462.694359  5577.503988   \n",
       "9306      0.0000     10.5230      4.8424   91.871486   472.079746   \n",
       "9309      0.0000     10.9900      7.1321  213.520118  2696.776875   \n",
       "9310      0.0000     10.5990      8.1287  178.866286  1879.712774   \n",
       "9311      0.0000      6.4823      4.0771   89.433691   355.824549   \n",
       "9312      0.0000     17.9030      5.7323  476.940794  4794.236478   \n",
       "9321      0.0000     26.8560     18.3260  431.474963  6311.881900   \n",
       "9323      0.0000     47.6720     37.1120  148.644044   921.541618   \n",
       "9324      0.0000      6.3276      4.2714   88.626625   375.112771   \n",
       "9325      0.0000      0.0000      4.5000  236.404198  1922.878354   \n",
       "9328      0.0000     25.7220     16.9150  366.985413  3817.323403   \n",
       "9343      0.0000     11.3220      7.6258  353.445190  7464.020802   \n",
       "9346      0.0000      8.9094      5.4171  681.828395  6870.268200   \n",
       "9361      0.0000      0.0000      4.0000  188.860351   785.240245   \n",
       "9379      0.0000      7.8926      3.9517  123.867586   747.094415   \n",
       "9395      0.0000      6.2597      3.9638   63.769752   208.166747   \n",
       "9410      0.0000     11.8060      4.3860   64.872840   181.890278   \n",
       "9426      0.0000      6.0949      4.4083  130.450836   938.374900   \n",
       "9458      0.0000      7.0179      4.7674   56.280399   133.566004   \n",
       "9460      0.0000     10.5110      6.8862  268.106349  3078.929633   \n",
       "9481      0.0000      7.1706      5.1042   84.231701   406.946663   \n",
       "9485      1.0084     18.1490      3.0532   41.443501    83.173844   \n",
       "\n",
       "      Simple Volume  Simple Surface Area  Latitude Quadrant  \\\n",
       "0       1050.510885         10303.293150                134   \n",
       "4        541.099705          8927.413959                130   \n",
       "6       1489.274248          6953.727742                 23   \n",
       "7        580.542076          7817.986839                 24   \n",
       "17         6.776716          5110.582173                 20   \n",
       "37      3393.206061         17878.444612                 53   \n",
       "38      1840.953217         10165.902061                 54   \n",
       "46       925.649655          7834.208723                 45   \n",
       "59     11244.119950         27585.864459                 51   \n",
       "60      1522.323394         11359.992439                 54   \n",
       "61     35556.056588         27843.444169                 78   \n",
       "68     10483.955715         29040.883717                 63   \n",
       "69     10827.487921         41619.054015                 60   \n",
       "70      7283.749967         19034.787783                 63   \n",
       "75      6948.156183         22375.519478                 63   \n",
       "76       281.470823          3432.521596                 91   \n",
       "77     58510.545325         27124.006083                 74   \n",
       "78     15502.540260         15116.444333                 76   \n",
       "91     16021.542831         50333.090914                103   \n",
       "107      723.496651          9003.738700                106   \n",
       "118    27833.656849         26248.941234                 98   \n",
       "119     3816.497502          8421.211415                124   \n",
       "120    14702.819519         67615.559255                111   \n",
       "121    14313.137508         35085.623016                110   \n",
       "122     8077.283891         14066.617857                108   \n",
       "123    14609.370146         14185.569959                111   \n",
       "130     4336.248653         23381.735801                125   \n",
       "137     1391.238999         11619.827741                132   \n",
       "140     2455.701547         13723.358799                140   \n",
       "152    20000.046451         60151.946864                172   \n",
       "...             ...                  ...                ...   \n",
       "9251     125.808706          3702.470687                333   \n",
       "9272   22956.798594         49820.020507                338   \n",
       "9281     782.441160          8222.800977                376   \n",
       "9286   10460.524311         34789.675730                354   \n",
       "9287    6345.593058         18830.706012                357   \n",
       "9289     939.326437          7838.298710                353   \n",
       "9294    3140.772595         19809.630797                346   \n",
       "9296    1127.945005         10277.425804                349   \n",
       "9300   34081.895872         72154.318799                341   \n",
       "9306    2285.998962         13761.793582                346   \n",
       "9309   19233.682352         37379.935090                400   \n",
       "9310   15279.621224         30355.769037                402   \n",
       "9311    1450.732270         14215.778681                403   \n",
       "9312   27482.001763         84063.254807                398   \n",
       "9321  115671.547697         72705.789391                373   \n",
       "9323   34200.252519         25832.002277                374   \n",
       "9324    1602.256689         13567.053597                380   \n",
       "9325    8652.952594         39812.055044                401   \n",
       "9328   64570.025362         65807.706484                375   \n",
       "9343   56919.129831         69928.707974                411   \n",
       "9346   37216.929867        119293.708343                408   \n",
       "9361    3140.960978         20287.240105                338   \n",
       "9379    2952.293001         21911.406828                369   \n",
       "9395     825.131352          7603.694732                375   \n",
       "9410     797.770760          7632.847189                356   \n",
       "9426    4136.638071         17680.868540                397   \n",
       "9458     636.762566          6673.360979                394   \n",
       "9460   21202.125237         32522.740580                372   \n",
       "9481    2077.137158         10600.774629                403   \n",
       "9485     253.946380          3474.347194                 72   \n",
       "\n",
       "      Longitude Quadrant  \n",
       "0                     49  \n",
       "4                     50  \n",
       "6                     89  \n",
       "7                     89  \n",
       "17                    90  \n",
       "37                    76  \n",
       "38                    78  \n",
       "46                    84  \n",
       "59                    72  \n",
       "60                    75  \n",
       "61                    71  \n",
       "68                    71  \n",
       "69                    70  \n",
       "70                    71  \n",
       "75                    79  \n",
       "76                    73  \n",
       "77                    76  \n",
       "78                    76  \n",
       "91                    58  \n",
       "107                   58  \n",
       "118                   51  \n",
       "119                   64  \n",
       "120                   68  \n",
       "121                   66  \n",
       "122                   67  \n",
       "123                   67  \n",
       "130                   61  \n",
       "137                   61  \n",
       "140                   54  \n",
       "152                   46  \n",
       "...                  ...  \n",
       "9251                 429  \n",
       "9272                 444  \n",
       "9281                 441  \n",
       "9286                 447  \n",
       "9287                 446  \n",
       "9289                 442  \n",
       "9294                 434  \n",
       "9296                 436  \n",
       "9300                 433  \n",
       "9306                 435  \n",
       "9309                 424  \n",
       "9310                 427  \n",
       "9311                 421  \n",
       "9312                 421  \n",
       "9321                 428  \n",
       "9323                 426  \n",
       "9324                 426  \n",
       "9325                 422  \n",
       "9328                 431  \n",
       "9343                 426  \n",
       "9346                 421  \n",
       "9361                 461  \n",
       "9379                 450  \n",
       "9395                 467  \n",
       "9410                 462  \n",
       "9426                 472  \n",
       "9458                 478  \n",
       "9460                 481  \n",
       "9481                 478  \n",
       "9485                 244  \n",
       "\n",
       "[2060 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred:Apartment</th>\n",
       "      <th>pred:Commercial</th>\n",
       "      <th>pred:Industrial</th>\n",
       "      <th>pred:Institutional</th>\n",
       "      <th>pred:Office</th>\n",
       "      <th>pred:Small Commercial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true:Apartment</th>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Commercial</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Industrial</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Institutional</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Office</th>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true:Small Commercial</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       pred:Apartment  pred:Commercial  pred:Industrial  \\\n",
       "true:Apartment                    110                0                0   \n",
       "true:Commercial                     9                0                1   \n",
       "true:Industrial                     6                0               10   \n",
       "true:Institutional                 26                0                2   \n",
       "true:Office                        40                0                1   \n",
       "true:Small Commercial              57                0                5   \n",
       "\n",
       "                       pred:Institutional  pred:Office  pred:Small Commercial  \n",
       "true:Apartment                          1            7                     47  \n",
       "true:Commercial                         2            3                     25  \n",
       "true:Industrial                         1            0                     22  \n",
       "true:Institutional                      4            6                     40  \n",
       "true:Office                             0           24                     35  \n",
       "true:Small Commercial                   3           15                    116  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultDF\n",
    "#apartment and Small commercial are fairly dominant, this is interesting. Can we regroup the categories and see if this is impactful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_test, y_test_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Domestic Typology Reshuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:warmup]",
   "language": "python",
   "name": "conda-env-warmup-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
